{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudorandom numbers\n",
    "In this section we focus on `jax.random` and pseudo random number generation (PRNG); that is, the process of algorithmically generating sequences of numbers whose properties approximate the properties of sequences of random numbers sampled from an appropriate distribution.\n",
    "\n",
    "PRNG-generated sequences are not truly random because they are actually determined by their initial value, which is typically referred to as the `seed`, and each step of random sampling is a deterministic function of some `state` that is carried over from a sample to the next.\n",
    "\n",
    "Pseudo random number generation is an essential component of any machine learning or scientific computing framework. Generally, JAX strives to be compatible with NumPy, but pseudo random number generation is a notable exception.\n",
    "\n",
    "To better understand the difference between the approaches taken by JAX and NumPy when it comes to random number generation we will discuss both approaches in this section.\n",
    "\n",
    "### Random numbers in NumPy\n",
    "Pseudo random number generation is natively supported in NumPy by the `numpy.random` module. In NumPy, pseudo random number generation is based on a global `state`, which can be set to a deterministic initial condition using `numpy.random.seed()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MT19937', array([         0,          1, 1812433255, 1900727105, 1208447044,\n",
      "       2481403966, 4042607538,  337614300, 3232553940, 1018809052,\n",
      "       3202401494, 1775180719, 3192392114,  594215549,  184016991,\n",
      "        829906058,  610491522, 3879932251, 3139825610,  297902587,\n",
      "       4075895579, 2943625357, 3530655617, 1423771745, 2135928312,\n",
      "       2891506774, 1066338622,  135451537,  933040465, 2759011858,\n",
      "       2273819758, 3545703099, 2516396728, 127 ...\n"
     ]
    }
   ],
   "source": [
    "def print_truncated_random_state():\n",
    "  \"\"\"To avoid spamming the outputs, print only part of the state.\"\"\"\n",
    "  full_random_state = np.random.get_state()\n",
    "  print(str(full_random_state)[:460], '...')\n",
    "\n",
    "print_truncated_random_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MT19937', array([         0,          1, 1812433255, 1900727105, 1208447044,\n",
      "       2481403966, 4042607538,  337614300, 3232553940, 1018809052,\n",
      "       3202401494, 1775180719, 3192392114,  594215549,  184016991,\n",
      "        829906058,  610491522, 3879932251, 3139825610,  297902587,\n",
      "       4075895579, 2943625357, 3530655617, 1423771745, 2135928312,\n",
      "       2891506774, 1066338622,  135451537,  933040465, 2759011858,\n",
      "       2273819758, 3545703099, 2516396728, 127 ...\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print_truncated_random_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MT19937', array([2443250962, 1093594115, 1878467924, 2709361018, 1101979660,\n",
      "       3904844661,  676747479, 2085143622, 1056793272, 3812477442,\n",
      "       2168787041,  275552121, 2696932952, 3432054210, 1657102335,\n",
      "       3518946594,  962584079, 1051271004, 3806145045, 1414436097,\n",
      "       2032348584, 1661738718, 1116708477, 2562755208, 3176189976,\n",
      "        696824676, 2399811678, 3992505346,  569184356, 2626558620,\n",
      "        136797809, 4273176064,  296167901, 343 ...\n"
     ]
    }
   ],
   "source": [
    "_ = np.random.uniform()\n",
    "print_truncated_random_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5488135  0.71518937 0.60276338]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print(np.random.uniform(size=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individually: [0.5488135  0.71518937 0.60276338]\n",
      "all at once:  [0.5488135  0.71518937 0.60276338]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print(\"individually:\", np.stack([np.random.uniform() for _ in range(3)]))\n",
    "\n",
    "np.random.seed(0)\n",
    "print(\"all at once: \", np.random.uniform(size=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random numbers in JAX\n",
    "JAX’s random number generation differs from NumPy’s in important ways, because NumPy’s PRNG design makes it hard to simultaneously guarantee a number of desirable properties. Specifically, in JAX we want PRNG generation to be:\n",
    "\n",
    "1. reproducible,\n",
    "\n",
    "2. parallelizable,\n",
    "\n",
    "3. vectorisable.\n",
    "\n",
    "We will discuss why in the following. First, we will focus on the implications of a PRNG design based on a global state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9791922366721637\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "def bar(): return np.random.uniform()\n",
    "def baz(): return np.random.uniform()\n",
    "\n",
    "def foo(): return bar() + 2 * baz()\n",
    "\n",
    "print(foo())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `foo` sums two scalars sampled from a uniform distribution.\n",
    "\n",
    "The output of this code can only satisfy requirement #1 if we assume a predictable order of execution for `bar()` and `baz()`. This is not a problem in NumPy, which always evaluates code in the order defined by the Python interpreter. In JAX, however, this is more problematic: for efficient execution, we want the JIT compiler to be free to reorder, elide, and fuse various operations in the function we define. Further, when executing in multi-device environments, execution efficiency would be hampered by the need for each process to synchronize a global state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicit random state\n",
    "To avoid this issue, JAX avoids implicit global random state, and instead tracks state explicitly via a random `key`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array((), dtype=key<fry>) overlaying:\n",
      "[ 0 42]\n"
     ]
    }
   ],
   "source": [
    "from jax import random\n",
    "\n",
    "key = random.key(42)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.18471177\n",
      "-0.18471177\n"
     ]
    }
   ],
   "source": [
    "print(random.normal(key))\n",
    "print(random.normal(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw 0: 1.369469404220581\n",
      "draw 1: -0.19947023689746857\n",
      "draw 2: -2.298278331756592\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "  new_key, subkey = random.split(key)\n",
    "  del key  # The old key is consumed by split() -- we must never use it again.\n",
    "\n",
    "  val = random.normal(subkey)\n",
    "  del subkey  # The subkey is consumed by normal().\n",
    "\n",
    "  print(f\"draw {i}: {val}\")\n",
    "  key = new_key  # new_key is safe to use in the next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = random.split(key)\n",
    "key, *forty_two_subkeys = random.split(key, num=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lack of sequential equivalence\n",
    "Another difference between NumPy’s and JAX’s random modules relates to the sequential equivalence guarantee mentioned above.\n",
    "\n",
    "As in NumPy, JAX’s random module also allows sampling of vectors of numbers. However, JAX does not provide a sequential equivalence guarantee, because doing so would interfere with the vectorization on SIMD hardware (requirement #3 above).\n",
    "\n",
    "In the example below, sampling 3 values out of a normal distribution individually using three subkeys gives a different result to using giving a single key and specifying `shape=(3,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "individually: [-0.04838832  0.10796154 -1.2226542 ]\n",
      "all at once:  [ 0.18693547 -1.2806505  -1.5593132 ]\n"
     ]
    }
   ],
   "source": [
    "key = random.key(42)\n",
    "subkeys = random.split(key, 3)\n",
    "sequence = np.stack([random.normal(subkey) for subkey in subkeys])\n",
    "print(\"individually:\", sequence)\n",
    "\n",
    "key = random.key(42)\n",
    "print(\"all at once: \", random.normal(key, shape=(3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorized: [-0.04838832  0.10796154 -1.2226542 ]\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "print(\"vectorized:\", jax.vmap(random.normal)(subkeys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX PRNG Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a PRNG design that\n",
    "\n",
    "1. is **expressive** in that it is convenient to use and it doesn’t constrain the user’s ability to write numerical programs with exactly the behavior that they want,\n",
    "\n",
    "2. enables **reproducible** program execution in a backend-independent way,\n",
    "\n",
    "3. has semantics that are **invariant to `@jit` compilation boundaries and device backends**,\n",
    "\n",
    "4. enables **vectorization for generating array values** using SIMD hardware,\n",
    "\n",
    "5. is **parallelizable** in that it doesn’t add sequencing constraints between random function calls that otherwise would have no data dependence,\n",
    "\n",
    "6. scales to multi-replica, multi-core, and distributed computation,\n",
    "\n",
    "7. **fits with JAX and XLA semantics** and design philosophies (which are ultimately motivated by other practical concerns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Three programming models and toy example programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(): return bar() + baz()\n",
    "def bar(): return rand(RNG, (3, 4))\n",
    "def baz(): return rand(RNG, (3, 4))\n",
    "def main():\n",
    "  global RNG\n",
    "  RNG = RandomState(0)\n",
    "  return foo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve reproducibility here we would need to control the order of evaluation for bar() and baz() even though there is no explicit data dependence from one to the other. This kind of sequencing requirement stemming from reproducibility (#2) violates parallelizability (#5) and doesn’t fit with JAX or XLA’s functional semantics (#6) in which subexpressions can be evaluated in any order. Even if we didn’t require reproducibility and thus allowed any evaluation order, parallelization across calls (#5) would still be made difficult by the need to update shared state. Moreover, because the same PRNG state would need to be accessed and maintained in both Python and any compiled code, this model would likely lead to engineering challenges to achieve compilation invariance (#3) and scaling to multiple replicas (#6). Finally, the expressiveness is limited (#1) because there is no way for foo() to call bar() or baz() without affecting its own (implicit) PRNG state.\n",
    "\n",
    "Whether the model supports vectorization (#4) depends on some additional details. In Numpy, PRNG vectorization is limited by a sequential-equivalent guarantee:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76405235, 0.40015721])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "rng.randn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.76405235, 0.40015721])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "np.stack([rng.randn() for _ in range(2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow for vectorization (#4) within primitive PRNG function calls that generate arrays (e.g. to rand() with a shape argument), we drop this sequential-equivalent guarantee. This vectorization can be supported by any of the three programming models discussed in this section, though it motivates the implementation in terms of a counter-based PRNG as described in the next section.\n",
    "\n",
    "The stateful PRNG user programming model is not promising. Here’s an example of a functional model but lacking a key ingredient that we call splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(rng_1):\n",
    "   y, rng_2 = baz(rng_1)\n",
    "   z, rng_3 = bar(rng_2)\n",
    "   return y + z, rng_3\n",
    "\n",
    "def bar(x, rng):\n",
    "  val, new_rng = rand(rng, (3, 4))\n",
    "  return val, new_rng\n",
    "\n",
    "def baz(x, rng):\n",
    "  val, new_rng = rand(rng, (3, 4))\n",
    "  return val, new_rng\n",
    "\n",
    "def main():\n",
    "  foo(RandomState(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model explicitly threads the PRNG state through all functions (primitive or non-primitive) that generate random values: that is, every random function must both accept and return the state. Now there is an explicit data dependence between the call to baz() and the call to bar() in foo(), so the data flow (and hence sequencing) is made explicit and fits with JAX’s existing semantics (#7), unlike in the previous model. This explicit threading can also make the semantics invariant to compilation boundaries (#3).\n",
    "\n",
    "Explicit threading is inconvenient for the programmer. But worse, it hasn’t actually improved the expressiveness (#1): there is still no way for foo() to call into bar() or baz() while maintaining its own PRNG state. Without knowledge of their callers or the subroutines they call, functions must defensively pass in and return the rng state everywhere. Moreover, it also doesn’t improve the prospects for parallelization (#5) or scaling to multiple replicas (#6) because everything is still sequential, even if the sequencing is made explicit in the functional programming sense.\n",
    "\n",
    "In short, making the code functional by explicitly threading state isn’t enough to achieve our expressiveness (#1) and performance (#5, #6) goals.\n",
    "\n",
    "The key problem in both the previous models is that there’s too much sequencing. To reduce the amount of sequential dependence we use functional splittable PRNGs. Splitting is a mechanism to ‘fork’ a new PRNG state into two PRNG states while maintaining the usual desirable PRNG properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foo(rng_1):\n",
    "   rng_2, rng_3 = split(rng_1, 2)\n",
    "   return bar(rng_2) + baz(rng_3)\n",
    "\n",
    "def bar(x, rng):\n",
    "  return rand(rng, (3, 4))\n",
    "\n",
    "def baz(x, rng):\n",
    "  return rand(rng, (3, 4))\n",
    "\n",
    "def main():\n",
    "  foo(RandomState(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some points to notice:\n",
    "\n",
    "1. there is no sequential dependence between the calls to bar() and baz() and they can be evaluated in either order without affecting the value of the result, which solves the remaining performance goals (#5, #6),\n",
    "\n",
    "2. functions do not need to return updated versions of PRNGs and it is straightforward to call a random subroutine without affecting existing PRNG states, improving the expressiveness (#1) from the other functional model.\n",
    "\n",
    "The example doesn’t show it, but as a consequence of the choice (2) the only way to advance the PRNG state is to call split(). That is, we have two ways to achieve (1), and they differ in whether they burden the user program with explicit calls to split(), as in the above example, or instead burden the user program with explicit threading. We prefer the former, i.e. the version with explicit splitting, because we can easily implement the explicit-threading version in terms of it.\n",
    "\n",
    "## Design\n",
    "We can use the counter-based PRNG design, and in particular the Threefry hash function, as described in Parallel random numbers: as easy as 1, 2, 3. We use the counter to achieve efficient vectorization: for a given key we can generate an array of values in a vectorized fashion by mapping the hash function over a range of integers [k + 1, …, k + sample_size]. We use the key together with the hash function to implement splittable PRNGs: that is, splitting is a way to generate two new keys from an existing one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`type Sample = Int256`\n",
    "`type Key = Sample  -- important identification for splitting`\n",
    "`type Count = Int32`\n",
    "\n",
    "`hash :: Key -> Count -> Int256  -- output type equal to Key and Sample`\n",
    "\n",
    "`split :: Key -> (Key, Key)`\n",
    "`split key = (hash key 0, hash key 1)`\n",
    "\n",
    "`draw_samples :: Key -> Int -> [Sample]`\n",
    "`draw_samples key n = map (hash key) [1..n]`\n",
    "\n",
    "Surprisingly, drawing a sample is very similar to splitting! The key is the difference in the type of the output (even though the types are identified): in one case the value is to be used in forming random samples of interest (e.g. turning random bits into a Float representing a random normal) while in the other case the value is to be used as a key for further hashing.\n",
    "\n",
    "The asymmetry in the hash function arguments, of type Key and Count, is that the latter is trivial and computationally cheap to advance by an arbitrary amount, since we just need to increase the integer value, while the former is only advanced by hashing. That’s why we use the count argument for vectorization.\n",
    "\n",
    "## More realistic example user programs\n",
    "Here’s what a training loop on the host might look like when the step requires a PRNG (maybe for dropout or for VAE training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Dropout(rate, mode='train'):\n",
    "  def init_fun(input_shape):\n",
    "    return input_shape, ()\n",
    "  def apply_fun(rng, params, inputs):\n",
    "    if mode == 'train':\n",
    "      keep = lax.random.bernoulli(rng, rate, inputs.shape)\n",
    "      return np.where(keep, inputs / rate, 0)\n",
    "    else:\n",
    "      return inputs\n",
    "  return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial(*layers):\n",
    "  init_funs, apply_funs = zip(*layers)\n",
    "  def init_fun(input_shape):\n",
    "    ...\n",
    "  def apply_fun(rng, params, inputs):\n",
    "    rngs = split(rng, len(layers))\n",
    "    for rng, param, apply_fun in zip(rngs, params, apply_funs):\n",
    "      inputs = apply_fun(rng, param, inputs)\n",
    "    return inputs\n",
    "  return init_fun, apply_fun\n",
    "\n",
    "def parallel(*layers):\n",
    "  init_funs, apply_funs = zip(*layers)\n",
    "  def init_fun(input_shape):\n",
    "    ...\n",
    "  def apply_fun(rng, params, inputs):\n",
    "    rngs = split(rng, len(layers))\n",
    "    return [f(r, p, x) for f, r, p, x in zip(apply_funs, rngs, params, inputs)]\n",
    "  return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tradeoffs and alternatives\n",
    "1. We’re not exploiting any device hardware PRNG\n",
    "\n",
    "    * We don’t currently have enough control over the hardware PRNG’s state for all backends.\n",
    "\n",
    "    * Even if we did, it would be backend-dependent and we might have to introduce sequential dependencies between random calls to ensure deterministic ordering and hence reproducibility.\n",
    "\n",
    "    * We don’t know of any workloads for which the software PRNG should become a bottleneck.\n",
    "\n",
    "    * We could consider providing an additional API that allows access to a hardware PRNG for users who want to give up other desiderata (like strict reproducibility).\n",
    "\n",
    "2. We give up the sequential equivalent guarantee, in which creating a random array in one call produces the same values as creating the flattened array one random element at a time.\n",
    "\n",
    "    * This property is likely incompatible with vectorization (a high priority).\n",
    "\n",
    "    * We don’t know of any users or examples for which this property is important.\n",
    "\n",
    "    * Users could write a layer on top of this API to provide this guarantee.\n",
    "\n",
    "3. We can’t follow the `numpy.random` API exactly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
